Hereâ€™s a simple distributed application using Hadoop MapReduce to process a system log file and count the number of visits per URL:

---

## **1. Problem Statement**

Given a log file where each line represents a request (e.g., web server logs), count the total number of visits to each URL.

---

## **2. MapReduce Application Outline**

- **Input:** Log file stored in HDFS, each line contains fields like timestamp, IP, URL, etc.
- **Output:** For each URL, the total number of visits.

---

## **3. Mapper Logic**

- Read each log line.
- Parse the URL field.
- Emit `` for each occurrence[5][4].

---

## **4. Reducer Logic**

- For each URL key, sum all the counts.
- Emit ``[5][4].

---

## **5. Sample Java Code**

```java
public class LogProcessor {
  public static class LogMapper extends Mapper {
    private final static IntWritable one = new IntWritable(1);
    private Text url = new Text();

    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
      String[] fields = value.toString().split(" "); // Adjust delimiter as per your log format
      if(fields.length > 2) {
        url.set(fields[2]); // Assuming URL is the third field
        context.write(url, one);
      }
    }
  }

  public static class SumReducer extends Reducer {
    public void reduce(Text key, Iterable values, Context context) throws IOException, InterruptedException {
      int sum = 0;
      for(IntWritable val : values) {
        sum += val.get();
      }
      context.write(key, new IntWritable(sum));
    }
  }
}
```

---

## **6. Run the Application**

- Compile and package as a JAR.
- Upload your log file to HDFS.
- Run with:  
  ```
  hadoop jar logprocessor.jar LogProcessor /input/logfile /output/result
  ```
- Output: Each line shows a URL and its visit count[5][1].

---

**This approach efficiently processes large log files in parallel using Hadoop MapReduce, making it scalable for big data environments.**

Citations:
[1] https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html
[2] https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html
[3] https://stackoverflow.com/questions/23689653/how-to-process-a-log-file-using-mapreduce
[4] https://airccse.org/journal/iju/papers/4313iju04.pdf
[5] https://www.acceldata.io/blog/hadoop-mapreduce-for-big-data-success-real-world-use-cases-and-solutions
[6] https://www.tutorialspoint.com/hadoop/hadoop_mapreduce.htm
[7] https://www.vskills.in/certification/tutorial/log4j-logging-log-levels-stack-trace-and-metrics-3/

---
Answer from Perplexity: https://www.perplexity.ai/search/import-java-io-ioexception-imp-xh1uAkeYSxGHTfUR_6P05Q?utm_source=copy_output
